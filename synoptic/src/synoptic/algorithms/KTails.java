package synoptic.algorithms;

import java.util.ArrayList;
import java.util.Collections;
import java.util.LinkedHashMap;
import java.util.LinkedHashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.logging.Logger;

import synoptic.algorithms.graphops.PartitionMultiMerge;
import synoptic.model.ChainsTraceGraph;
import synoptic.model.Partition;
import synoptic.model.PartitionGraph;
import synoptic.model.event.EventType;
import synoptic.model.interfaces.INode;
import synoptic.model.interfaces.ITransition;
import synoptic.util.InternalSynopticException;
import synoptic.util.NotImplementedException;

/**
 * Implements the KTails algorithm as defined in Biermann & Feldman '72.
 */
public class KTails {
    public static Logger logger;
    static {
        logger = Logger.getLogger("KTails");
    }

    /**
     * Constructs and returns a PartitionGraph generated by applying kTails with
     * the given k value to the given trace graph
     */
    public static PartitionGraph performKTails(ChainsTraceGraph g, int k) {
        PartitionGraph pGraph = new PartitionGraph(g, false, null);
        attemptMerge(pGraph, k);
        return pGraph;
    }

    /**
     * Finds all possible merges in pGraph. Requires making a new call to
     * attemptMerge after every merge in case previously un-merge-able pairs
     * become merge-able.
     */
    private static void attemptMerge(PartitionGraph pGraph, int k) {
        // Keeps track of the merges that we want to perform.
        Set<PartitionMultiMerge> merges = new LinkedHashSet<PartitionMultiMerge>();

        // List of all partitions -- needed for ordering partitions in the loops
        // below.
        List<Partition> partitions = new ArrayList<Partition>(pGraph.getNodes());

        // Partitions that belong to a merge.
        List<Partition> mergedPartitions = new ArrayList<Partition>();

        // Maps a partition to the set of strings of length <= k reachable from
        // the partition.
        Map<Partition, Set<List<EventType>>> kStringsMap = new LinkedHashMap<Partition, Set<List<EventType>>>();

        int remaining = partitions.size();

        // Build the kStringsMap
        for (Partition P : partitions) {
            logger.info("Remaining = " + remaining);
            remaining -= 1;
            Set<List<EventType>> prefixes = new LinkedHashSet<List<EventType>>();
            List<EventType> prefix = new ArrayList<EventType>();
            prefix.add(P.getEType());
            prefixes.add(prefix);

            Set<List<EventType>> ret = null;
            if (k == 0) {
                // For k=0, use singleton prefixes set containing P's event
                // type.
                ret = prefixes;
            } else {
                for (Partition child : P.getAllSuccessors()) {
                    if (ret == null) {
                        ret = getKString(child, k - 1, prefixes);
                    } else {
                        ret.addAll(getKString(child, k - 1, prefixes));
                    }
                }
            }
            // If we have not explored anything below P because it is a leaf
            // then use singleton prefix set.
            if (ret == null) {
                ret = prefixes;
            }
            kStringsMap.put(P, ret);
        }

        for (int i = 0; i < partitions.size(); i++) {
            Partition Pi = partitions.get(i);

            // Skip partition Pi if it has already been merged previously.
            // Since k-equivalence is transitive, this merge already contains
            // all the k-equivalent partitions.
            if (mergedPartitions.contains(Pi)) {
                continue;
            }

            // m will track all partitions to be merged with Pi.
            PartitionMultiMerge m = null;

            // Can't merge a partition with itself. So skip i=j. Also, merging
            // is commutative so if we've tried merge(p1,p2)w then we don't have
            // to try/check merge(p2,p1). So skip j < i.
            for (int j = i + 1; j < partitions.size(); j++) {
                Partition Pj = partitions.get(j);
                // If we merged p1 and p2 previously, and now we are merging
                // p2 and p3, then p3 _must_ be in the p1-p2 partition, since we
                // must have already compared the ktails of p1 and p3
                // previously.
                if (mergedPartitions.contains(Pj)) {
                    continue;
                }

                if (!kStringsMap.get(Pi).equals(kStringsMap.get(Pj))) {
                    continue;
                }

                if (m == null) {
                    List<Partition> list = new ArrayList<Partition>();
                    list.add(Pj);
                    m = new PartitionMultiMerge(Pi, list);
                    merges.add(m);
                } else {
                    m.addToMerge(Pj);
                }

                // We don't need to add Pi to mergedPartitions, since we
                // will never come back to it in the check above.
                mergedPartitions.add(Pj);

            }
        }

        for (PartitionMultiMerge merge : merges) {
            pGraph.apply(merge);
        }

        return;
        /*
         * TODO: old topological-version of k-equivalence. Refactor and keep
         * this code in case we want to use it later.
         * 
         * 
         * for (Partition p : pGraph.getNodes()) { for (Partition q :
         * pGraph.getNodes()) { if (p == q) { // Can't merge a partition with
         * itself continue; }
         * 
         * // For all k, can only merge p and q if their event types match. if
         * (!(p.getEType().equals(q.getEType()))) { continue; }
         * 
         * if (kEquals(p, q, k, false)) { // Merge partitions that are
         * k-equivalent pGraph.apply(new PartitionMerge(p, q));
         * 
         * // Now attempt merges in modified graph attemptMerge(pGraph, k);
         * return; } } }
         */
    }

    private static Set<List<EventType>> getKString(Partition P, int k,
            Set<List<EventType>> parentPrefixes) {
        if (k < 0) {
            return Collections.emptySet();
        }

        Set<List<EventType>> newPrefixes = new LinkedHashSet<List<EventType>>();

        for (List<EventType> prefix : parentPrefixes) {
            // Have to copy the prefix into newPrefixes, completely!
            List<EventType> prefixCopy = new ArrayList<EventType>();
            prefixCopy.addAll(prefix);
            prefixCopy.add(P.getEType());
            newPrefixes.add(prefixCopy);
        }

        if (k == 0) {
            return newPrefixes;
        }

        Set<List<EventType>> ret = null;
        for (Partition child : P.getAllSuccessors()) {
            if (ret == null) {
                ret = getKString(child, k - 1, newPrefixes);
            } else {
                ret.addAll(getKString(child, k - 1, newPrefixes));
            }
        }

        return ret;
    }

    /**
     * We perform k-tails comparison on the message graph to the given depth k.
     * At k=0 we are just comparing the labels of the two nodes, k > 0 compares
     * the subgraphs that extend down k levels. <br />
     * <br />
     * TODO: differentiate between weak subsumption and strong subsumption? As
     * is done here: http://portal.acm.org/ft_gateway.cfm?id=1368157&type=pdf
     * 
     * @return true if the k-tails are equivalent under the current definition
     *         of equivalence.
     */
    static public <NodeType extends INode<NodeType>> boolean kEquals(
            NodeType n1, NodeType n2, int k, boolean subsumption) {
        if (!n1.getEType().equals(n2.getEType())) {
            return false;
        }
        if (k == 0) {
            return n1.getEType().equals(n2.getEType());
        }

        if (subsumption) {
            return kEqualsWithSubsumption(n1, n2, k);
        }
        LinkedHashMap<NodeType, NodeType> allVisitedMatches = new LinkedHashMap<NodeType, NodeType>();
        return kEqualsWithoutSubsumption(n1, n2, k, allVisitedMatches);
    }

    /**
     * With subsumption its okay for some transitions of n1 to be unmatched with
     * any transitions in n2, but all of n2 transitions must be matched to some
     * transition in n1.
     */
    static private <NodeType extends INode<NodeType>> boolean kEqualsWithSubsumption(
            NodeType n1, NodeType n2, int k) {

        throw new NotImplementedException(
                "kTails with Subsumption unimplemented.");

        // // The labels must match.
        // if (!n1.getLabel().equals(n2.getLabel())) {
        // return false;
        // }
        //
        // // Base case.
        // if (k == 0) {
        // return true;
        // }
        //
        // // Short circuit: even with subsumption all of n2 transitions must
        // map
        // // to exactly one n1 transition. Therefore number of n2 transition
        // must
        // // be less than number of n1 transitions.
        // if (n1.getTransitions().size() < n2.getTransitions().size()) {
        // return false;
        // }
        //
        // // Here we will match up transition destinations between n1 and n2
        // based
        // // on whether or not they are kEqual with k=k-1. Because of
        // subsumption
        // // we have to keep track of all possible matches, since we don't know
        // // a-priori which ones to match to exactly (another node might need
        // to
        // // match to the one we've matched to previously).
        // LinkedHashMap<NodeType, NodeType> childKEquivMatches = new
        // LinkedHashMap<NodeType, NodeType>();
    }

    /**
     * Without subsumption the children sets of both nodes must match each other
     * exactly -- there needs to be a 1-1 correspondence that holds recursively.
     */
    static private <NodeType extends INode<NodeType>> boolean kEqualsWithoutSubsumption(
            NodeType n1, NodeType n2, int k,
            LinkedHashMap<NodeType, NodeType> allVisitedMatches) {

        // ////////////////
        // Documented in Issue 258.
        // FIXME: this comparison should be independent of topology -- i.e., we
        // should be comparing the set of k-length strings generated from n1 and
        // n2, regardless of the paths that we took to generate them.
        // ////////////////

        // The labels must match.
        if (!n1.getEType().equals(n2.getEType())) {
            return false;
        }

        if (allVisitedMatches.containsKey(n1)) {
            if (allVisitedMatches.get(n1) != n2) {
                // n1 has been visited previously, but it doesn't map to n2
                return false;
            }
        } else {
            if (allVisitedMatches.containsValue(n2)) {
                // n1 has not been visited previously, but n2 has been.
                return false;
            }
        }

        // Base case.
        if (k == 0) {
            return true;
        }

        // Short circuit: since we are not subsuming, the number of transitions
        // from the two nodes must be the same.
        // NOTE: this comparison considers all relations simultaneously. For
        // efficiency we could also check for matching transition counts for
        // each relation.

        List<? extends ITransition<NodeType>> n1Trans = n1.getAllTransitions();
        List<? extends ITransition<NodeType>> n2Trans = n2.getAllTransitions();

        if (n1Trans.size() != n2Trans.size()) {
            return false;
        }

        // Here we will match up children of n1 with children of n2 based
        // on whether or not they are kEqual with k=k-1. We keep track of
        // n2 children that we've already matched to some children of n1. We
        // skip these matched children of n2 since we can't reuse matches for
        // children of n1.

        // If any of the children of n1 have been previously visited, then check
        // that each visited child of n1 corresponds to some visited child of
        // n2. And that no visited child of n2 is visited otherwise.
        LinkedHashSet<NodeType> visitedN1Children = new LinkedHashSet<NodeType>();
        LinkedHashSet<NodeType> visitedN2Children = new LinkedHashSet<NodeType>();

        for (ITransition<NodeType> t : n1Trans) {
            NodeType c1 = t.getTarget();
            if (allVisitedMatches.containsKey(c1)) {
                visitedN1Children.add(c1);
                visitedN2Children.add(allVisitedMatches.get(c1));
            }
        }

        int numVisitedN2ChildrenFound = 0;
        for (ITransition<NodeType> t : n2Trans) {
            NodeType c2 = t.getTarget();
            if (allVisitedMatches.containsValue(c2)) {
                if (!visitedN2Children.contains(c2)) {
                    // c2 has been visited but doesn't map to a visited child of
                    // n1.
                    return false;
                }
                numVisitedN2ChildrenFound++;
            } else {
                if (visitedN2Children.contains(c2)) {
                    // c2 has not been visited but _does_ map to a visited child
                    // of n1 -- visitedMatches hash is therefore inconsistent.
                    throw new InternalSynopticException(
                            "Inconsistent kTails exploration.");
                }
            }
        }
        // We were not able to find all visitedN2Children as children of n2.
        if (numVisitedN2ChildrenFound != visitedN2Children.size()) {
            return false;
        }

        // Below, we are going to skip nodes that have been previously visited
        // -- those in visitedN1Children and visitedN2Children.

        // This set contains a child of n2 if that child has been
        // mapped in some earlier iteration of the outer loop (through children
        // of n2) below.
        LinkedHashSet<NodeType> childKEquivMatches = new LinkedHashSet<NodeType>();

        // Record that we're _currently_ visiting n1 and n2 -- this is
        // necessary for cycles (for DAGs it is sufficient to mark n1
        // and n2 as visited after determining that they are kEqual).
        allVisitedMatches.put(n1, n2);

        for (ITransition<NodeType> t1 : n1Trans) {
            NodeType c1 = t1.getTarget();
            // Skip c1 if it was visited by this method earlier.
            if (visitedN1Children.contains(c1)) {
                continue;
            }

            boolean kEqual = false;

            // Make sure to get transitions of the same relation.
            for (ITransition<NodeType> t2 : n2
                    .getTransitionsWithExactRelations(t1.getRelation())) {
                NodeType c2 = t2.getTarget();

                // Skip c2 if it was visited by this method earlier.
                if (visitedN2Children.contains(c2)) {
                    continue;
                }

                // Skip c2 if its already been mapped to a c1 previously in the
                // outer loop.
                if (childKEquivMatches.contains(c2)) {
                    continue;
                }

                if (kEqualsWithoutSubsumption(c1, c2, k - 1, allVisitedMatches)) {
                    kEqual = true;
                    childKEquivMatches.add(c2);
                    break;
                }
            }
            // Could not find any kEqual c2 to match with c1.
            if (!kEqual) {
                // Remove the record of visiting n1 and n2.
                allVisitedMatches.remove(n1);
                return false;
            }
        }
        // TODO: update this description for loops
        // We are k-equivalent at this point because:
        // 0. Labels of n1 and n2 match
        // 1. The child sets have the same size
        // 2. Each child of n1 matches to exactly one child of n2
        // 3. Each pair of matched children are k-1 equivalent.
        return true;
    }
}
