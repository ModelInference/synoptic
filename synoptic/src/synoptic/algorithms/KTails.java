package synoptic.algorithms;

import java.util.ArrayList;
import java.util.Collections;
import java.util.LinkedHashMap;
import java.util.LinkedHashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.logging.Logger;

import synoptic.algorithms.graphops.PartitionMultiMerge;
import synoptic.model.ChainsTraceGraph;
import synoptic.model.Partition;
import synoptic.model.PartitionGraph;
import synoptic.model.event.EventType;
import synoptic.model.interfaces.INode;

/**
 * Implements the KTails algorithm as defined in Biermann & Feldman '72.
 */
public class KTails {
    public static Logger logger;
    static {
        logger = Logger.getLogger("KTails");
    }

    /**
     * Constructs and returns a PartitionGraph generated by applying kTails with
     * the given k value to the given trace graph
     */
    public static PartitionGraph performKTails(ChainsTraceGraph g, int k) {
        // Note: at k == 0, all "states" should be considered equal, but an
        // event-based model cannot express this, thus the assert.
        assert (k > 0);

        PartitionGraph pGraph = new PartitionGraph(g, false, null);
        kTails(pGraph, k);
        return pGraph;
    }

    /**
     * Finds and executes all possible k-equivalent merges in pGraph.
     */
    private static void kTails(PartitionGraph pGraph, int k) {
        // Note: at k == 0, all "states" should be considered equal, but an
        // event-based model cannot express this, thus the assert.
        assert (k > 0);

        // Keeps track of the merges that we want to perform.
        Set<PartitionMultiMerge> merges = new LinkedHashSet<PartitionMultiMerge>();

        // List of all partitions -- needed for ordering partitions in the loops
        // below.
        List<Partition> partitions = new ArrayList<Partition>(pGraph.getNodes());

        // Partitions that belong to a merge.
        List<Partition> mergedPartitions = new ArrayList<Partition>();

        // Maps a partition to the set of strings of length <= k reachable from
        // the partition.
        // TODO: this is inefficient, ideally we would Map sets of strings to
        // partitions with those sets!
        Map<Partition, Set<List<EventType>>> kStringsMap = new LinkedHashMap<Partition, Set<List<EventType>>>();

        // int remaining = partitions.size();
        // Build the kStringsMap
        logger.fine("Pre-computing [node -> ktail set] map");
        for (Partition P : partitions) {
            // logger.info("Remaining kTails pre-mining = " + remaining);
            // remaining -= 1;

            Set<List<EventType>> ret = getNodeKStrings(P, k);
            kStringsMap.put(P, ret);
        }

        logger.fine("Pre-computed map: " + kStringsMap.toString());

        // remaining = partitions.size();
        logger.fine("Finding sets of nodes that are k-equivalent.");
        for (int i = 0; i < partitions.size(); i++) {
            // logger.info("Remaining kTails n^2 checking = " + remaining);
            // remaining -= 1;
            Partition Pi = partitions.get(i);

            // Skip partition Pi if it has already been merged previously.
            // Since k-equivalence is transitive, this merge already contains
            // all the k-equivalent partitions.
            if (mergedPartitions.contains(Pi)) {
                continue;
            }

            // m will track all partitions to be merged with Pi.
            PartitionMultiMerge m = null;

            Set<List<EventType>> PiKStrings = kStringsMap.get(Pi);

            // Can't merge a partition with itself. So skip i=j. Also, merging
            // is commutative so if we've tried merge(p1,p2), then we don't have
            // to try/check merge(p2,p1). So skip j < i.
            for (int j = i + 1; j < partitions.size(); j++) {
                Partition Pj = partitions.get(j);
                // If we merged p1 and p2 previously, and now we are merging
                // p2 and p3, then p3 _must_ be in the p1+p2 partition, since we
                // must have already compared the ktails of p1 and p3
                // previously.
                if (mergedPartitions.contains(Pj)) {
                    continue;
                }

                Set<List<EventType>> PjKStrings = kStringsMap.get(Pj);
                if (!PiKStrings.equals(PjKStrings)) {
                    continue;
                }

                logger.fine("Merging " + Pi + " and " + Pj);

                if (m == null) {
                    List<Partition> list = new ArrayList<Partition>();
                    list.add(Pj);
                    m = new PartitionMultiMerge(Pi, list);
                    merges.add(m);
                } else {
                    m.addToMerge(Pj);
                }

                // We don't need to add Pi to mergedPartitions, since we
                // will never come back to it in the check above.
                mergedPartitions.add(Pj);
            }
        }

        logger.fine("Applying merges.");
        for (PartitionMultiMerge merge : merges) {
            pGraph.apply(merge);
        }

        return;

    }

    static public <NodeType extends INode<NodeType>> boolean kEquals(
            NodeType n1, NodeType n2, int k) {
        // Note: at k == 0, all "states" should be considered equal, but an
        // event-based model cannot express this, thus the assert.
        assert (k > 0);

        if (k == 1) {
            return n1.getEType().equals(n2.getEType());
        }

        // Optimization.
        if (!n1.getEType().equals(n2.getEType())) {
            return false;
        }

        Set<List<EventType>> n1Strings = getNodeKStrings(n1, k);
        Set<List<EventType>> n2Strings = getNodeKStrings(n2, k);
        if (n1Strings.equals(n2Strings)) {
            return true;
        }
        return false;
    }

    /**
     * @param k
     * @param P
     * @return
     */
    private static <NodeType extends INode<NodeType>> Set<List<EventType>> getNodeKStrings(
            NodeType P, int k) {
        assert (k >= 0);

        if (k == 0) {
            return Collections.emptySet();
        }

        Set<List<EventType>> prefixes = new LinkedHashSet<List<EventType>>();
        List<EventType> prefix = new ArrayList<EventType>();
        prefix.add(P.getEType());
        prefixes.add(prefix);

        Set<List<EventType>> ret = new LinkedHashSet<List<EventType>>();
        ret.addAll(prefixes);
        for (NodeType child : P.getAllSuccessors()) {
            // note: prefixes cannot mutate during this loop.
            ret.addAll(getNodeKStringHelper(child, k - 1, prefixes));
        }
        return ret;
    }

    /**
     * Helper for getNodeKString. Returns a set of lists of EventTypes, which
     * represents a set of strings that are of length <= k and which can be
     * constructed by starting at P.
     * 
     * @param P
     * @param k
     * @param parentPrefixes
     *            : cannot be modified.
     * @return
     */
    private static <NodeType extends INode<NodeType>> Set<List<EventType>> getNodeKStringHelper(
            NodeType P, int k, Set<List<EventType>> parentPrefixes) {
        assert (k >= 0);

        if (k == 0) {
            return Collections.emptySet();
        }

        Set<List<EventType>> newPrefixes = new LinkedHashSet<List<EventType>>();

        for (List<EventType> prefix : parentPrefixes) {
            // Have to copy the prefix into newPrefixes, completely!
            List<EventType> prefixCopy = new ArrayList<EventType>();
            prefixCopy.addAll(prefix);
            prefixCopy.add(P.getEType());
            newPrefixes.add(prefixCopy);
        }

        if (k == 1) {
            return newPrefixes;
        }

        // We always return at least the new prefixes we've constructed.
        Set<List<EventType>> ret = newPrefixes;
        for (NodeType child : P.getAllSuccessors()) {
            ret.addAll(getNodeKStringHelper(child, k - 1, newPrefixes));
        }

        return ret;
    }

}
